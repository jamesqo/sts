\subsection{Introduction}

Typically, big-O notation is used to analyze the time or space complexity of a function. In order to highlight the benefit of growth arrays, however, I will use the $\sim$ relation to analyze complexity. This is because for certain operations, growth arrays are only better than dynamic arrays by a constant factor. For example, dynamic arrays might use roughly $2n$ space for appending $n$ items, while growth arrays would use roughly $n$ space. Even though growth arrays are clearly better in this regard, the big-O space complexity for both data structures would be the same, $O(n)$.

My goal is to be able to compare the coefficients of the highest-order terms in both expressions. For example, I would like to take the ratio $2n / n$, see that it is $2$, and conclude that dynamic arrays allocate roughly twice as much as growth arrays for large $n$. However, big-O notation does not support this.

\subsection{Definitions}

I will mainly use the $\sim$ relation to analyze complexity. It is defined as follows:
\begin{align*}
f \sim g \Biconditional \ExprNToInfty \frac f g = 1
\end{align*}
This is read as "$f$ is asymptotic to $g$" or "$f$ and $g$ are asymptotic." {\HdrNote} $f$ and $g$ are used as shorthand to denote $f(n)$ and $g(n)$, respectively.

Notice that while $O(2n) = O(n)$, $2n \not\sim n$. Thus, $\sim$ makes it possible to distinguish between a function that uses $n$ space and one that uses $2n$ space. {\HdrNote} A consequence of this is that bases for logarithms cannot be omitted, like in big-O notation.

I will also introduce the cousins of $\sim$, $\FluteLess$ and $\FluteLeq$. $f \FluteLeq g$ if and only if $f \FluteLess g$ or $f \sim g$. $\FluteLess$ is defined as follows:
\begin{align*}
f \FluteLess g \Biconditional \ExprNToInfty \frac f g < 1
\end{align*}
\subsection{Properties}
\label{subsec:AsymptoticProperties}

Here, I define various properties of the $\sim$ relation that will be used in my proofs. These properties themselves are proved in the appendix.

The following theorem states that $\sim$ can "merge", or un-distribute, over addition, multiplication, and division. This is a property shared with big-O.

\begin{theorem}
\label{thm:MergesOverOps}
	Suppose $f$, $\Tweak{f}$, $g$, and $\Tweak{g}$ are functions. If $f \sim \Tweak{f}$ and $g \sim \Tweak{g}$, then
	\begin{align*}
	f + g &\sim \Tweak{f} + \Tweak{g}\\
	fg &\sim \Tweak{f}\Tweak{g}\\
	\frac{f}{g} &\sim \frac {\Tweak{f}} {\Tweak{g}}
	\end{align*}
\end{theorem}

The following theorem states that lower-order terms may be removed: for example, $(n + \log_2 n) \sim n$. This is also a property shared with big-O.

\begin{theorem}
\label{thm:RemovesLowerOrderTerms}
	If $\ExprNToInfty \dfrac{g}{f} = 0$, then $f + O(g) \sim f$.
\end{theorem}

The following theorem states that $\sim$ is a transitive relation. This property is used implicitly by proofs that chain multiple $\sim$s in the form $f \sim g \sim h$, then conclude that $f \sim h$.

\begin{theorem}
\label{thm:Transitivity}
	If $f \sim g$ and $g \sim h$, then $f \sim h$.
\end{theorem}

The following theorem states that if two functions are asymptotic, then they belong to the same big-O class.

\begin{theorem}
\label{thm:SameBigOClass}
	If $f \sim g$ and $g = O(h)$, then $f = O(h)$.
\end{theorem}