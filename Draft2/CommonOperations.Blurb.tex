In this section, I implement common operations for dynamic and growth arrays, and analyze their time complexity. I also analyze space complexity of operations that allocate memory.

In order to highlight the benefit of growth arrays, I must define a new notation for time complexity. The reason for this is, for certain operations, growth arrays are only better than dynamic arrays by a constant factor. For example, dynamic arrays might allocate roughly $2\varnitems$ memory for appending $\varnitems$ items, while growth arrays would allocate roughly $\varnitems$ memory. Even though growth arrays are clearly better in this regard, the big-O space complexity for both data structures would be the same, $\bigo(\varnitems)$.

My goal is to be able to compare the coefficients of the highest-order terms in both expressions. For example, I would like to take the ratio $\frac{2\varnitems}{\varnitems}$, see that it is $2$, and conclude that dynamic arrays allocate roughly twice as much as growth arrays for large $\varnitems$.

To do this, I define an alternative to big-O, which I will call "big-P notation". I define $\biggo(f(n))$ to be the class of functions $g$ such that $g(n) \to f(n)$ for large $n$. Formally,

$$
g \in \biggo(f(n)) \leftrightarrow \lim_{n \to \infty} \frac{g(n)}{f(n)} = 1
$$

Like $\bigo$, $\biggo$ can be distributed and "un-distributed" over arithmetic operations. I define

\begin{align*}
\biggo(f(n)) + \biggo(g(n)) &:= \biggo(f(n) + g(n))\\
\biggo(f(n)) - \biggo(g(n)) &:= \biggo(f(n) - g(n))\\
\biggo(f(n)) \cdot \biggo(g(n)) &:= \biggo(f(n) \cdot g(n))\\
\frac {\biggo(f(n))} {\biggo(g(n))} &:= \biggo\left(\frac{f(n)} {g(n)}\right)
\end{align*}

Notice that while $\bigo(2\varnitems) = \bigo(\varnitems)$, $\biggo(2\varnitems) \neq \biggo(\varnitems)$. However, $\biggo$ still retains some nice properties of $\bigo$. In particular, it eliminates lower-order terms from consideration: $\biggo(n) = \biggo(n + \log_2 n)$, for example. This is stated formally in the following theorem:

\begin{theorem}
\label{ScrubsLowerOrderTerms}
	If $\lim_{n \to \infty} \frac{g(n)}{f(n)} = 0$, then $\biggo(f(n) + g(n)) = \biggo(f(n))$.
\end{theorem}

To prove this, we will need the following lemma.

\begin{lemma}
\label{UniqueClassOfFunctions}
	Each function $f(n)$ has a unique class of functions under $\biggo$. That is, suppose $f \in \biggo(g(n))$ and $f \in \biggo(h(n))$. Then $\biggo(g(n)) = \biggo(h(n))$.
\end{lemma}

\begin{proof}
	By definition, $\lim_{n \to \infty} \frac{f(n)}{g(n)} = 1$ and $\lim_{n \to \infty} \frac{f(n)}{h(n)} = 1$. Flipping the first equation and multiplying, we receive
	
	\begin{align*}
	\left( \lim_{n \to \infty} \frac {g(n)} {f(n)} \right) \left( \lim_{n \to \infty} \frac {f(n)} {h(n)} \right) &= 1\\
	\lim_{n \to \infty} \frac {g(n)} {h(n)} &= 1\\
	g &\in \biggo(h(n))
	\end{align*}
	
	Now, consider any $g' \in \biggo(g(n))$. Since
	
	\begin{align*}
	\lim_{n \to \infty} \frac {g'(n)} {g(n)} &= 1\\
	\left( \lim_{n \to \infty} \frac {g'(n)} {g(n)} \right) \left( \lim_{n \to \infty} \frac{g(n)}{h(n)} \right) &= 1\\
	\lim_{n \to \infty} \frac{g'(n)}{h(n)} &= 1
	\end{align*}
	
	it follows that $g' \in \biggo(h(n))$, and thus $\biggo(g(n)) \subseteq \biggo(h(n))$. By a similar argument, it can be shown $\biggo(h(n)) \subseteq \biggo(g(n))$. Thus it must be true that $\biggo(g(n)) = \biggo(h(n))$.
\end{proof}

Now \ref{ScrubsLowerOrderTerms} can be proved as follows:

\begin{proof}
	\begin{align*}
		\lim_{n \to \infty} \frac{f(n) + g(n)}{f(n)} &= \lim_{n \to \infty} \frac{f(n)}{f(n)} + \lim_{n \to \infty}\\ \frac{g(n)}{f(n)}\\
		&= 1 + 0\\
		&= 1
	\end{align*}
	
	Then $f(n) + g(n) \in \biggo(f(n))$. Since it is also true that $f(n) + g(n) \in \biggo(f(n) + g(n))$, it follows from \ref{UniqueClassOfFunctions} that $\biggo(f(n)) = \biggo(f(n) + g(n))$.
\end{proof}

The following mathematical definitions will be used while analyzing time and space complexity:

\begin{itemize}
	\item $\biggo(f(n))$ - This is an alternative to big-O notation that I will name "big-P notation". It is similar to big-O, but it preserves the coefficient of the fastest-growing term in $f(n)$. For example, $\bigo(2n) = \bigo(n)$, but $\biggo(2n) \neq \biggo(n)$. This makes it possible to compare two time complexities, if their ratio tends to a constant for large $n$.\\
	More formally, $\biggo(f(n)) = \biggo(g(n))$ iff $$\lim_{n \to \infty} {\frac{f(n)}{g(n)}} = 1$$.
\end{itemize}