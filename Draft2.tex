\documentclass{article}
\usepackage{amsmath}

\newcommand{\descriptn}{\textbf{Description}}
\newcommand{\dynarrayimpl}{\textbf{Dynamic array implementation}}
\newcommand{\funarrayimpl}{\textbf{Funnel array implementation}}
\newcommand{\tcomplex}{\textbf{Time complexity}}
\newcommand{\scomplex}{\textbf{Space complexity}}
\newcommand{\tcomplexcmp}{\textbf{Time complexity comparison}}
\newcommand{\scomplexcmp}{\textbf{Space complexity comparison}}

\newcommand{\timefn}{T}
\newcommand{\spacefn}{S}
\newcommand{\nwritesfn}{W}

\newcommand{\timenewfn}{\timefn'}
\newcommand{\spacenewfn}{\spacefn'}
\newcommand{\nwritesnewfn}{\nwritesfn'}

\newcommand{\timeratio}{r_\timefn}
\newcommand{\spaceratio}{r_\spacefn}

\newcommand{\bigo}{O}
\newcommand{\biggo}{P}
\newcommand{\varnitems}{n}
\newcommand{\indexertime}{I}

\newcommand{\listname}{L}

\newcommand{\initcapacity}{C_f}
\newcommand{\growthfactor}{G}
\newcommand{\capacityfn}{C}

\setlength{\parskip}{1em}

\begin{document}
	\begin{abstract}
	\end{abstract}

	\section{Introduction}
	
	\section{Fields and Properties}
	
	I define some \textbf{fields} and \textbf{properties} (constant time methods that do not change state) for both types of arrays, so I may use them later to implement non-trivial methods.
	
	\section{Common Operations}
	
	In this section, I implement and analyze common operations for dynamic and funnel arrays. I compare both implementations' time complexities, and space complexities if the operation allocates memory.
	
	The following mathematical definitions will be used while analyzing time and space complexity:
	
	\begin{description}
		\item[$\biggo(f(n))$] This is an alternative to big-O notation that I will name "big-P notation". It is similar to big-O, but it preserves the coefficient of the fastest-growing term in $f(n)$. For example, $\bigo(2n) = \bigo(n)$, but $\biggo(2n) \neq \biggo(n)$. This makes it possible to compare two time complexities, if their ratio tends to a constant for large $n$.\\
		More formally, $\biggo(f(n)) = \biggo(g(n))$ iff $$\lim_{n \to \infty} {\frac{f(n)}{g(n)}} = 1$$.
	\end{description}
	
	\subsection{Adding}
	
	\descriptn
	
	Adding is the most common operation done on dynamic arrays\footnote{}. Funnel arrays improve the performance of adding in two ways: by allocating less memory, and reducing the amount of copying. We begin with the implementation for dynamic arrays.
	
	I will first implement and analyze adding for dynamic arrays. Let $\listname$ be a dynamic array. The following definitions are used in the code:
	
	\begin{description}
		\item[initial capacity] The capacity of a dynamic a array when one item is added to it. I denote this $\initcapacity$.\\
		(The capacity of any dynamic array with size zero should be zero.)
		\item[growth factor] The factor by which the current capacity is multiplied to get the new capacity when $\listname$ is resized. I denote this with $\growthfactor$.
	\end{description}
	
	% impl.
	
	Before I analyze the time complexity of [add], I consider a different method for measuring its cost. Suppose I start with an empty list and $\varnitems$ elements are added. How many times is an element stored in an array? I will term the answer to this question the \textbf{write cost} of $\varnitems$ adds, and denote it $\nwritesfn(n)$.
	
	In the above code, one write is performed after the conditional, so it is apparent that $\nwritesfn(\varnitems) \geq \varnitems$ after $n$ adds. However, [resize] also does some writing, so in order to find a precise formula for $\nwritesfn(\varnitems)$ I need to analyze when [resize] is called. Consider the following lemma:
	
	[lemma]
	Let $\listname$ by a dynamic array. As $\varnitems$ are added, the sequence of capacities $\listname$ takes on is $$S_C = 0,\ \initcapacity,\ \growthfactor\initcapacity,\ \growthfactor^2\initcapacity,\ \ldots\ \growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil}\initcapacity$$.
	
	[proof]
	The capacity starts out at zero and becomes $\initcapacity$ once one element is added. From then on, it can only grow by a factor of $\growthfactor$ via [resize], so if $\growthfactor^i\initcapacity$ is the current capacity then $\growthfactor^{i + 1}\initcapacity$ must be the next capacity. By induction, the rest of the sequence is $$\left\{ \growthfactor^i\initcapacity \right\}_{i = 1}^k$$ for some $k$. Since the capacity is only as big as is needs to be, namely greater than or equal to $\varnitems$, $k$ is the smallest integer for which $\growthfactor^k\initcapacity \geq \varnitems$. Using this property, we now derive $k$.
	
	\begin{align*}
	\growthfactor^k\initcapacity &\geq \varnitems\\
	\growthfactor^k &\geq \frac{\varnitems}{\initcapacity}\\
	k &\geq \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity\\
	k &\geq \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity > k - 1\\
	k &= \big\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \big\rceil
	\end{align*}
	
	Then the final term in the sequence is $\growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil}\initcapacity$, completing the proof.
	
	Now, consider that to grow by $\growthfactor$ we have to call [resize]. So $\growthfactor^k\initcapacity$ being present in $S_C$ means we once called [resize] at size $\growthfactor^{k - 1}\initcapacity$ for $k \geq 1$. Then we must have called [resize] at the sizes $$S_R = 0,\ \initcapacity,\ \growthfactor\initcapacity,\ \growthfactor^2\initcapacity,\ \ldots\ \growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil - 1}\initcapacity$$
	
	Each time [resize] is called, we copy $i$ items where $i$ is the current size of the dynamic array. Then the total number of items copied for $\varnitems$ adds is
	
	\begin{align*}
	0 + \initcapacity + \growthfactor\initcapacity + \ldots + \growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil - 1}\initcapacity &= \left( \frac{\growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil} - 1}{\growthfactor - 1} \right) \initcapacity
	\end{align*}
	
	Finally, adding the writes made for every item in [add], I finally find an explicit formula for $\nwritesfn(\varnitems)$.
	
	$$
	\nwritesfn(\varnitems) = n + \left( \frac{\growthfactor^{\lceil \log_{\growthfactor} \varnitems - \log_{\growthfactor} \initcapacity \rceil} - 1}{\growthfactor - 1} \right) \initcapacity
	$$
		
	\begin{align*}
	\nwritesfn(\varnitems) = \biggo(2\varnitems)
	\end{align*}
	
	\scomplex
	
	\begin{align*}
	\spacefn(\varnitems) = \biggo(2^{\lceil \log_2 \varnitems \rceil + 1}) = \bigo(\varnitems)
	\end{align*}
	
	\funarrayimpl
	
	\tcomplex
	
	\begin{align*}
	\nwritesnewfn(\varnitems) = \biggo(\varnitems)
	\end{align*}
	
	\scomplex
	
	\begin{align*}
	\spacenewfn(\varnitems) = \biggo(2^{\lceil \log_2 \varnitems \rceil}) = \bigo(\varnitems)
	\end{align*}
	
	\tcomplexcmp
	
	\begin{align*}
	\end{align*}
	
	\scomplexcmp
	
	\begin{align*}
	\spaceratio = \frac {\biggo(2^{\lceil \log_2 \varnitems \rceil})} {\biggo(2^{\lceil \log_2 \varnitems \rceil + 1})} = \frac{1}{2}
	\end{align*}
	
	\subsection{Indexing}
	
	\descriptn
	
	Indexing is another very common operation on a list. I will call methods that get or set an item at a specified index \textbf{get indexer} and \textit{set indexers}, respectively.
	
	\dynarrayimpl
	
	\tcomplex
	
	$\timefn(\varnitems) = \bigo(1)$
	
	% <funnel array implementation>
	
	\tcomplex
	
	$\timenewfn(\varnitems) = \bigo(1)$
	
	\tcomplexcmp
	
	\subsection{Iterating}
	
	\descriptn
	
	\textbf{Iteration} of a list is the process of performing some action on each of its elements.
	
	\dynarrayimpl
	
	\tcomplex
	
	Ignoring the arbitrary code run after getting each element, the time complexity of this method is $\bigo(\varnitems)$.
	
	\funarrayimpl
	
	\tcomplex
	
	$\timenewfn(\varnitems) = \bigo(\varnitems)$
	
	\tcomplexcmp
	
	\subsection{Copying to an array}
	
	\descriptn
	
	Users often want to take list structures, such as dynamic arrays, and convert them into plain arrays. There are multiple reasons why someone would want to do this after they are done adding to the list:
	
	\begin{itemize}
		\item Plain arrays hold on to exactly the amount of memory needed to hold their elements. However, dynamic and funnel arrays allocate more space than necessary to optimize adding new items.
		\item The user wants to call a function in third-party code that takes a plain array as an argument.
		\item
		\item Plain arrays are contiguous, while funnel arrays are fragmented and have worse locality.
		\item The indexer of funnel arrays is several times slower than that of plain arrays, whether the $\bigo(1)$ or $\bigo(\log \varnitems)$ implementation is chosen.
	\end{itemize}
	
	\dynarrayimpl
	
	\tcomplex
	
	\funarrayimpl
	
	\tcomplex
	
	\section{Other Operations}
	
	\subsection{Inserting}
	
	\descriptn
	
	\textbf{Inserting} an element places it at a specified index within the list, and increments the list's count. If the index equals the size of the list, the effect is the same as adding the element. Otherwise, the elements at indices greater than or equal to the specified index are moved to the next index, then the element is placed at the specified index.
	
	\subsection{Deleting}
	
	\descriptn
	
	\textbf{Deleting} the element at a specified index moves the elements at indices greater than the specified index to the previous index. The count of the list is decremented.
	
	\subsection{Searching}
	
	\descriptn
	
	\textbf{Searching} for an element returns the first or last index within the list where the item can be found. If the user knows the items of the lists are sorted, \textbf{binary search} can be used.
	
	\subsection{In-place sorting}
	
	\descriptn
	
	Given a strict ordering $<$, we say a list $\listname$ is \textbf{sorted} by $<$ iff $\left(a, b \in \listname \land a < b\right) \leftrightarrow I_M(a) < I_m(b)$. $I_M(a)$ is the last (maximum) index of $a$ in $L$, and $I_m(b)$ is the first (minimum) index of $b$ in $L$. Note that the use of $<$ on the right-hand side compares integers and not elements of $L$, so this is not a recursive definition.
	
	\section{Implementations}
	
	\section{Benchmarks}
	
	\section{Closing Remarks}

\end{document}
